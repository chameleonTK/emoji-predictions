{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdfbe6f-51a1-46e6-829d-d00e348e1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "def dump_jsonl(output_path, data, append=False, progress=False):\n",
    "    \"\"\"\n",
    "    Write list of objects to a JSON lines file.\n",
    "    \"\"\"\n",
    "    mode = 'a+' if append else 'w'\n",
    "    with open(output_path, mode, encoding='utf-8') as f:\n",
    "        if progress:\n",
    "            data = tqdm(data)\n",
    "            \n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + '\\n')\n",
    "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
    "\n",
    "def load_jsonl(input_path, verbose=True, progress=False) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        if progress:\n",
    "            f = tqdm(f)\n",
    "            \n",
    "        for line in f:\n",
    "                data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    \n",
    "    if verbose:\n",
    "        print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58705a27-d75f-4987-997b-c5d6d0b0a57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1ec3f5-5cb5-4824-a311-0af4f5ea6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_list = {\n",
    "    \"thai-emojification\": \"❤️😄😞🍴⚾\", # https://github.com/kobkrit/thai-emojification\n",
    "    \"top10-2023\": \"😂😍😘👌😭😒😊😩😁😏\", # top 10 2023  https://blog.emojipedia.org/10-years-of-emojipedia-10-years-of-record-breaking-emoji-popularity/\n",
    "    \"top10-2013\": \"😂🤣❤️🙏😭😍✨🔥😊🥰\", # top 10 2013  https://blog.emojipedia.org/10-years-of-emojipedia-10-years-of-record-breaking-emoji-popularity/\n",
    "    \"semeval2018-task2\": \"❤😍😂💕😊😘💪😉👌🇪🇸😎💙💜😜💞✨🎶💘\", # SemEval-2018 Task 2, Multilingual Emoji Prediction\n",
    "    \"emotion\": \"😤😡😰😱☺😆😢😭\", # grief, fear, rage, and love: https://psycnet.apa.org/record/2005-04422-003; James, W. (1922). The emotions. In C. G. Lange & W. James (Eds.), The emotions, Vol. 1, pp. 93–135). Williams & Wilkins Co. https://doi.org/10.1037/10735-003\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db3df3f-a83f-4a77-9a28-dfb306aa0aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger ['😠', '😡', '😤']\n",
      "anticipation ['👀', '💭', '💰']\n",
      "disgust ['👎', '😖', '😣']\n",
      "fear ['😨', '😱', '😰']\n",
      "joy ['☺', '😆', '😹']\n",
      "sadness ['😢', '😭', '💔']\n",
      "surprise ['‼', '❗', '😱']\n",
      "trust ['😙', '💕', '🌹']\n"
     ]
    }
   ],
   "source": [
    "# https://aclanthology.org/2020.emnlp-main.720/\n",
    "# EmoTag1200: Understanding the Association between Emojis and Emotions\n",
    "import pandas as pd\n",
    "scores = pd.read_csv(\"./_private/EmoTag1200-scores.csv\")\n",
    "\n",
    "emojis_list[\"EmoTag1200\"] = \"\"\n",
    "emo = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust']\n",
    "for e in emo:\n",
    "    rows = scores.sort_values(e, ascending = False).head(3).to_dict('records')\n",
    "    print(e, [r[\"emoji\"] for r in rows])\n",
    "    emojis_list[\"EmoTag1200\"] += \"\".join([r[\"emoji\"] for r in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874c975-31a7-437e-8894-6a9dbaceda94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e5b08c-6f0c-4a9c-b7a8-cfa9aaafd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate twitter search query urls from 2020-2024\n",
    "\n",
    "import emoji\n",
    "import random\n",
    "\n",
    "urls = []\n",
    "emojis_unique_list = {}\n",
    "emojis_str = \"\"\n",
    "for corpus_name in emojis_list:\n",
    "    emojis_str += emojis_list[corpus_name]\n",
    "\n",
    "for e in emoji.emoji_list(emojis_str):\n",
    "    if e['emoji'] in emojis_unique_list:\n",
    "        continue\n",
    "    \n",
    "    emojis_unique_list[e['emoji']] = e\n",
    "    for year in [2020, 2021, 2022, 2023, 2024]:\n",
    "        for m in range(1, 13):\n",
    "            mm = str(m)\n",
    "            if m < 10:\n",
    "                mm = f\"0{m}\"\n",
    "            url = f\"https://twitter.com/search?q=({e['emoji']})%20lang%3Ath%20until%3A{year}-{mm}-28%20since%3A{year}-{mm}-01%20-filter%3Areplies\"\n",
    "            urls.append(url)\n",
    "            \n",
    "# random.shuffle(urls)\n",
    "# import pandas as pd\n",
    "# pd.DataFrame({\"url\": urls}).to_csv(\"urls.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538e443",
   "metadata": {},
   "source": [
    "## Load Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5c9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1127ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 185750 records from _private/tweets.jsonl\n"
     ]
    }
   ],
   "source": [
    "tweetsv1 = load_jsonl(\"_private/tweets.jsonl\")\n",
    "for tw in tweetsv1:\n",
    "    if \"id\" not in tw:\n",
    "        continue\n",
    "        \n",
    "    tweets.append({\n",
    "        \"id\": tw[\"id\"],\n",
    "        \"text\": tw[\"text\"],\n",
    "        \"created_at\": tw[\"created_at\"],\n",
    "        \"author_id\": tw[\"author_id\"],\n",
    "        \"source\": \"v1\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79771aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18481 records from _private/tweets_with_keywords.jsonl\n"
     ]
    }
   ],
   "source": [
    "tweetsv2 = load_jsonl(\"_private/tweets_with_keywords.jsonl\")\n",
    "\n",
    "from datetime import datetime\n",
    "for tw in tweetsv2:\n",
    "    d = datetime.strptime(tw[\"timestamp\"], '%b %d, %Y · %H:%M %p %Z')\n",
    "    tweets.append({\n",
    "        \"id\": tw[\"id\"],\n",
    "        \"text\": tw[\"text\"],\n",
    "        \"created_at\": d.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"),\n",
    "        \"author\": tw[\"username\"],\n",
    "        \"source\": \"v2\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063f745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "tweetsv3 = []\n",
    "for f in listdir(\"_private/Data\"):\n",
    "    if isfile(join(\"_private/Data\", f)):\n",
    "        d = pd.read_csv(join(\"_private/Data\", f))\n",
    "        tweetsv3 += d.to_dict('records')\n",
    "        \n",
    "\n",
    "for tw in tweetsv3:\n",
    "    try:\n",
    "        d = datetime.strptime(tw[\"published_at\"], '%Y-%m-%d %H:%M:%S+00')\n",
    "\n",
    "        tweets.append({\n",
    "            \"id\": tw[\"internal_unique_id\"],\n",
    "            \"text\": tw[\"content\"],\n",
    "            \"created_at\": d.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"),\n",
    "            \"author_id\": tw[\"user_id\"],\n",
    "            \"source\": \"v3\",\n",
    "        })\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4abb5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import countthai\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from tqdm import tqdm\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'],\n",
    "    # NB: we do not annotate terms\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True, \n",
    "    segmenter=\"twitter\",\n",
    "    corrector=\"twitter\",\n",
    "    tokenizer=None,\n",
    ")\n",
    "\n",
    "filteredTweets = {}\n",
    "for tw in tqdm(tweets):\n",
    "    if countthai(tw[\"text\"]) < 50:\n",
    "        tw[\"removed\"] = True\n",
    "        continue\n",
    "        \n",
    "    tw[\"preprocessed\"] = text_processor.pre_process_doc(tw[\"text\"])\n",
    "    \n",
    "    if tw[\"id\"] in filteredTweets:\n",
    "        tw[\"removed\"] = True\n",
    "        continue\n",
    "    \n",
    "    if tw[\"preprocessed\"] in filteredTweets:\n",
    "        tw[\"removed\"] = True\n",
    "        continue\n",
    "    \n",
    "    tw[\"removed\"] = False\n",
    "    filteredTweets[tw[\"id\"]] = True\n",
    "    filteredTweets[tw[\"preprocessed\"]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a725c79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'แมวววววว'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processor.pre_process_doc(\"แมวววววว\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b632294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91ded813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 205897/205897 [01:23<00:00, 2469.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "# emoji in emojis_str is not unique\n",
    "tweetsByEmojiDict = {}\n",
    "for e in emoji.emoji_list(emojis_str):\n",
    "    tweetsByEmojiDict[e[\"emoji\"]] = {}\n",
    "\n",
    "dd = df[~df[\"removed\"]]\n",
    "for idx, row in tqdm(dd.iterrows(), total=len(dd)):\n",
    "    for e in emoji.emoji_list(emojis_str):\n",
    "        if e[\"emoji\"] in row[\"text\"]:\n",
    "            tweetsByEmojiDict[e[\"emoji\"]][row[\"id\"]] = row.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65024592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321818, 205897, 63.97932993182482)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(dd), len(dd)*100/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aac57137",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsByEmoji = {}\n",
    "for e in emoji.emoji_list(emojis_str):\n",
    "    tweetsByEmoji[e[\"emoji\"]] = list(tweetsByEmojiDict[e[\"emoji\"]].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774f23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16b9e414",
   "metadata": {},
   "source": [
    "#### Top numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4929074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😂 6983 [{'match_start': 0, 'match_end': 1, 'emoji': '😂'}]\n",
      "😭 6307 [{'match_start': 0, 'match_end': 1, 'emoji': '😭'}]\n",
      "❤ 6238 [{'match_start': 0, 'match_end': 1, 'emoji': '❤'}]\n",
      "❤️ 4587 [{'match_start': 0, 'match_end': 2, 'emoji': '❤️'}]\n",
      "😰 4477 [{'match_start': 0, 'match_end': 1, 'emoji': '😰'}]\n",
      "😤 4041 [{'match_start': 0, 'match_end': 1, 'emoji': '😤'}]\n",
      "🥰 3998 [{'match_start': 0, 'match_end': 1, 'emoji': '🥰'}]\n",
      "🤣 3813 [{'match_start': 0, 'match_end': 1, 'emoji': '🤣'}]\n",
      "🙏 3793 [{'match_start': 0, 'match_end': 1, 'emoji': '🙏'}]\n",
      "✨ 3634 [{'match_start': 0, 'match_end': 1, 'emoji': '✨'}]\n"
     ]
    }
   ],
   "source": [
    "tweetsByEmoji = {k: v for k, v in sorted(tweetsByEmoji.items(), key=lambda item: -len(item[1]))}\n",
    "\n",
    "cc = 0\n",
    "for e in tweetsByEmoji:\n",
    "    print(e, len(tweetsByEmoji[e]), emoji.emoji_list(e))\n",
    "    cc+= 1\n",
    "    if cc >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b38f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ff1f861",
   "metadata": {},
   "source": [
    "## Export them into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24e47f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thai-emojification\n",
      "Total records: 9132\n",
      "Count #labels: Counter({1: 8978, 2: 154})\n",
      "Wrote 9132 records to annotated/tweets_thai-emojification.jsonl\n",
      "\n",
      "top10-2023\n",
      "Total records: 26620\n",
      "Count #labels: Counter({1: 23352, 2: 2782, 3: 390, 4: 60, 5: 30, 6: 6})\n",
      "Wrote 26620 records to annotated/tweets_top10-2023.jsonl\n",
      "\n",
      "top10-2013\n",
      "Total records: 40775\n",
      "Count #labels: Counter({1: 29547, 2: 8838, 3: 1971, 4: 332, 5: 50, 6: 30, 7: 7})\n",
      "Wrote 40775 records to annotated/tweets_top10-2013.jsonl\n",
      "\n",
      "semeval2018-task2\n",
      "Total records: 39468\n",
      "Count #labels: Counter({1: 26808, 2: 9074, 3: 2583, 4: 640, 5: 175, 6: 144, 7: 28, 8: 16})\n",
      "Wrote 39468 records to annotated/tweets_semeval2018-task2.jsonl\n",
      "\n",
      "emotion\n",
      "Total records: 29083\n",
      "Count #labels: Counter({1: 26109, 2: 2596, 3: 291, 4: 72, 5: 15})\n",
      "Wrote 29083 records to annotated/tweets_emotion.jsonl\n",
      "\n",
      "EmoTag1200\n",
      "Total records: 48874\n",
      "Count #labels: Counter({1: 38914, 2: 8420, 3: 1179, 4: 222, 5: 90, 6: 26, 7: 23})\n",
      "Wrote 48874 records to annotated/tweets_EmoTag1200.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for corpus_name in emojis_list:\n",
    "    print(corpus_name)\n",
    "    \n",
    "    corpus = []\n",
    "    labels = {}\n",
    "    for e in emoji.emoji_list(emojis_list[corpus_name]):\n",
    "        for row in tweetsByEmoji[e[\"emoji\"]]:\n",
    "            if row[\"id\"] in labels:\n",
    "                labels[row[\"id\"]].add(e[\"emoji\"])\n",
    "            else:\n",
    "                labels[row[\"id\"]] = set([e[\"emoji\"]])\n",
    "    \n",
    "    count = Counter()\n",
    "    for e in emoji.emoji_list(emojis_list[corpus_name]):\n",
    "        for row in tweetsByEmoji[e[\"emoji\"]]:\n",
    "            corpus.append({**row, \"label\": list(labels[row[\"id\"]])})\n",
    "            \n",
    "            count[len(labels[row[\"id\"]])] += 1\n",
    "    \n",
    "    \n",
    "    print(\"Total records:\", len(corpus))\n",
    "    print(\"Count #labels:\", count)\n",
    "    \n",
    "    dump_jsonl(f\"annotated/tweets_{corpus_name}.jsonl\", corpus)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be7e8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a7331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15efd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994af35a",
   "metadata": {},
   "source": [
    "## Emotion Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4611e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grief 😢😭 7660\n",
      "fear 😰😱 7971\n",
      "rage 😤😡 6963\n",
      "love ☺😆 6489\n"
     ]
    }
   ],
   "source": [
    "emotions = {\"grief\": \"😢😭\", \"fear\": \"😰😱\", \"rage\": \"😤😡\", \"love\": \"☺😆\"}\n",
    "feelings = {}\n",
    "for emo in emotions:\n",
    "    n = 0\n",
    "    for e in emoji.emoji_list(emotions[emo]):\n",
    "        n += len(tweetsByEmoji[e[\"emoji\"]])\n",
    "        feelings[e[\"emoji\"]] = emo\n",
    "        \n",
    "    print(emo, emotions[emo], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2377598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dabcf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 205897/205897 [00:17<00:00, 11694.70it/s]\n",
      "/var/folders/lg/k6blptqs0rl4ds21k448syq80000gn/T/ipykernel_55474/957619678.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dd.loc[:, \"nEmoji\"] = nEmoji\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nEmoji</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "nEmoji        \n",
       "0       178372\n",
       "1        26109\n",
       "2         1298\n",
       "3           97\n",
       "4           18\n",
       "5            3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEmoji = []\n",
    "dd = df[~df[\"removed\"]]\n",
    "selectedSentences = []\n",
    "for idx, row in tqdm(dd.iterrows(), total=len(dd)):\n",
    "    cnt = 0\n",
    "    emojiInSentence = None\n",
    "    for e in emoji.emoji_list(emojis_list[\"emotion\"]):\n",
    "        if e[\"emoji\"] in row[\"text\"]:\n",
    "            cnt += 1\n",
    "            emojiInSentence = e\n",
    "            \n",
    "    nEmoji.append(cnt)\n",
    "    if cnt==1:\n",
    "        r = {**row.to_dict(), **emojiInSentence, \"feeling\": feelings[emojiInSentence[\"emoji\"]]}\n",
    "        selectedSentences.append(r)\n",
    "\n",
    "dd.loc[:, \"nEmoji\"] = nEmoji\n",
    "dd[[\"id\", \"nEmoji\"]].groupby(\"nEmoji\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46ba052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = pd.DataFrame(selectedSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf073565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>source</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>removed</th>\n",
       "      <th>author</th>\n",
       "      <th>match_start</th>\n",
       "      <th>match_end</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>7055</td>\n",
       "      <td>7055</td>\n",
       "      <td>7055</td>\n",
       "      <td>7028</td>\n",
       "      <td>7055</td>\n",
       "      <td>7055</td>\n",
       "      <td>7055</td>\n",
       "      <td>27</td>\n",
       "      <td>7055</td>\n",
       "      <td>7055</td>\n",
       "      <td>7055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>6746</td>\n",
       "      <td>6746</td>\n",
       "      <td>6746</td>\n",
       "      <td>6296</td>\n",
       "      <td>6746</td>\n",
       "      <td>6746</td>\n",
       "      <td>6746</td>\n",
       "      <td>450</td>\n",
       "      <td>6746</td>\n",
       "      <td>6746</td>\n",
       "      <td>6746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>6105</td>\n",
       "      <td>6105</td>\n",
       "      <td>6105</td>\n",
       "      <td>5944</td>\n",
       "      <td>6105</td>\n",
       "      <td>6105</td>\n",
       "      <td>6105</td>\n",
       "      <td>161</td>\n",
       "      <td>6105</td>\n",
       "      <td>6105</td>\n",
       "      <td>6105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rage</th>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>6186</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>17</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  text  created_at  author_id  source  preprocessed  removed  \\\n",
       "feeling                                                                     \n",
       "fear     7055  7055        7055       7028    7055          7055     7055   \n",
       "grief    6746  6746        6746       6296    6746          6746     6746   \n",
       "love     6105  6105        6105       5944    6105          6105     6105   \n",
       "rage     6203  6203        6203       6186    6203          6203     6203   \n",
       "\n",
       "         author  match_start  match_end  emoji  \n",
       "feeling                                         \n",
       "fear         27         7055       7055   7055  \n",
       "grief       450         6746       6746   6746  \n",
       "love        161         6105       6105   6105  \n",
       "rage         17         6203       6203   6203  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.groupby([\"feeling\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc8689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd.to_csv(\"annotated_misp/unannotated_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "34ad61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_balanced = []\n",
    "for f in nd[\"feeling\"].unique():\n",
    "    rows = nd[nd[\"feeling\"]==f].sample(n=2500)\n",
    "    nd_balanced.append(rows)\n",
    "\n",
    "nd_balanced = pd.concat(nd_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f5010e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>source</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>removed</th>\n",
       "      <th>author</th>\n",
       "      <th>match_start</th>\n",
       "      <th>match_end</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2488</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>12</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2107</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>393</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2352</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>148</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rage</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2491</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>9</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  text  created_at  author_id  source  preprocessed  removed  \\\n",
       "feeling                                                                     \n",
       "fear     2500  2500        2500       2488    2500          2500     2500   \n",
       "grief    2500  2500        2500       2107    2500          2500     2500   \n",
       "love     2500  2500        2500       2352    2500          2500     2500   \n",
       "rage     2500  2500        2500       2491    2500          2500     2500   \n",
       "\n",
       "         author  match_start  match_end  emoji  \n",
       "feeling                                         \n",
       "fear         12         2500       2500   2500  \n",
       "grief       393         2500       2500   2500  \n",
       "love        148         2500       2500   2500  \n",
       "rage          9         2500       2500   2500  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_balanced.groupby([\"feeling\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6a338ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_balanced = nd_balanced.sample(frac=1)\n",
    "nd_balanced.reset_index(inplace=True)\n",
    "# nd_balanced.to_csv(\"annotated_misp/unannotated_balanced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4d3479ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc28e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document \n",
    "\n",
    "nFile = 10\n",
    "perFile = len(nd_balanced)//nFile\n",
    "for i in range(nFile):\n",
    "\n",
    "    startIdx = i*perFile\n",
    "    endIdx = (i+1)*perFile\n",
    "    \n",
    "    document = Document()\n",
    "    table = document.add_table(rows = 1 , cols = 1)\n",
    "#     table.style = 'Table Grid'\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'ประโยค'     \n",
    "\n",
    "    cc = 0\n",
    "    for idx, row in tqdm(nd_balanced.iterrows(), total=nd_balanced.shape[0]):\n",
    "        if idx < startIdx:\n",
    "            continue\n",
    "        if idx >= endIdx:\n",
    "            continue\n",
    "        \n",
    "        cc += 1\n",
    "        row_cells = table.add_row().cells \n",
    "        row_cells[0].text = row[\"preprocessed\"]\n",
    "#     document.save(f'unannotated_balanced_p{i}.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6697c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>source</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>removed</th>\n",
       "      <th>author</th>\n",
       "      <th>match_start</th>\n",
       "      <th>match_end</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>277</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>197</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>35</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>249</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>14</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rage</th>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         level_0  index   id  text  created_at  author_id  source  \\\n",
       "feeling                                                             \n",
       "fear         280    280  280   280         280        277     280   \n",
       "grief        232    232  232   232         232        197     232   \n",
       "love         263    263  263   263         263        249     263   \n",
       "rage         225    225  225   225         225        224     225   \n",
       "\n",
       "         preprocessed  removed  author  match_start  match_end  emoji  \n",
       "feeling                                                                \n",
       "fear              280      280       3          280        280    280  \n",
       "grief             232      232      35          232        232    232  \n",
       "love              263      263      14          263        263    263  \n",
       "rage              225      225       1          225        225    225  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_balanced.iloc[0:1000].groupby(\"feeling\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd686c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
